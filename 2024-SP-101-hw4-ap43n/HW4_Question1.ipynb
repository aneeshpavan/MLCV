{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nq1S2lEvRN5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93bb83c1-3211-4bfb-f55f-4572a8b4734b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.26.1-py3-none-any.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.14.0)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.2.1)\n",
            "Installing collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.3.8 virtualenv-20.26.1\n",
            "created virtual environment CPython3.10.12.final.0-64 in 347ms\n",
            "  creator CPython3Posix(dest=/content/mlcv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==24.0, setuptools==69.5.1, wheel==0.43.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [830 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,756 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,037 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,077 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,371 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 7,306 kB in 1s (5,692 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.7-minimal libpython3.7-stdlib mailcap mime-support\n",
            "  python3.7-minimal\n",
            "Suggested packages:\n",
            "  python3.7-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.7-minimal libpython3.7-stdlib mailcap mime-support python3.7\n",
            "  python3.7-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 4,698 kB of archives.\n",
            "After this operation, 17.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.7-minimal amd64 3.7.17-1+jammy1 [608 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.7-minimal amd64 3.7.17-1+jammy1 [1,837 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.7-stdlib amd64 3.7.17-1+jammy1 [1,864 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.7 amd64 3.7.17-1+jammy1 [362 kB]\n",
            "Fetched 4,698 kB in 2s (2,571 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.7-minimal:amd64.\n",
            "(Reading database ... 121920 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.7-minimal_3.7.17-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.7-minimal:amd64 (3.7.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.7-minimal.\n",
            "Preparing to unpack .../1-python3.7-minimal_3.7.17-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.7-minimal (3.7.17-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.7-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.7-stdlib_3.7.17-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.7-stdlib:amd64 (3.7.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.7.\n",
            "Preparing to unpack .../5-python3.7_3.7.17-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.7 (3.7.17-1+jammy1) ...\n",
            "Setting up libpython3.7-minimal:amd64 (3.7.17-1+jammy1) ...\n",
            "Setting up python3.7-minimal (3.7.17-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.7-stdlib:amd64 (3.7.17-1+jammy1) ...\n",
            "Setting up python3.7 (3.7.17-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "update-alternatives: using /usr/bin/python3.7 to provide /usr/bin/python3 (python3) in auto mode\n",
            "There is only one alternative in link group python3 (providing /usr/bin/python3): /usr/bin/python3.7\n",
            "Nothing to configure.\n"
          ]
        }
      ],
      "source": [
        "!pip3 install virtualenv\n",
        "!virtualenv mlcv\n",
        "!source /content/mlcv/bin/activate;\n",
        "!sudo apt-get update -y\n",
        "\n",
        "!sudo apt-get install python3.7\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --config python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VmpPobHgRQlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbce96e2-1963-4423-ae00-a08a00c652d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.17\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3uqvt0psmsE"
      },
      "source": [
        "# Section 1: TCAV\n",
        "Please refer this source https://github.com/tensorflow/tcav on how you can import and run TCAV. The repository consists of an example (https://github.com/tensorflow/tcav/blob/master/Run_TCAV_on_colab.ipynb) of TCAV scores using GoogLeNet model trained on ImageNet dataset. The examples demonstrated the results based the concepts [\"dotted\",\"striped\",\"zigzagged\"] with target being 'zebra'.\n",
        "\n",
        "You are allowed to change the code template in accordance with the example provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MTquf1igRUZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4221ee50-7630-4d46-f85d-e69fb844b6e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,967 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.4 [1,305 kB]\n",
            "Fetched 1,677 kB in 1s (2,247 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 122565 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3.7-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.7-distutils python3.7-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 313 kB of archives.\n",
            "After this operation, 1,229 kB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.7-lib2to3 all 3.7.17-1+jammy1 [124 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.7-distutils all 3.7.17-1+jammy1 [189 kB]\n",
            "Fetched 313 kB in 1s (234 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3.7-lib2to3.\n",
            "(Reading database ... 123427 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.7-lib2to3_3.7.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.7-lib2to3 (3.7.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.7-distutils.\n",
            "Preparing to unpack .../python3.7-distutils_3.7.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.7-distutils (3.7.17-1+jammy1) ...\n",
            "Setting up python3.7-lib2to3 (3.7.17-1+jammy1) ...\n",
            "Setting up python3.7-distutils (3.7.17-1+jammy1) ...\n",
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<2.0,>=1.16.0\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting protobuf>=3.6.1\n",
            "  Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 KB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.4/503.4 KB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio>=1.8.6\n",
            "  Downloading grpcio-1.62.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt>=1.11.1\n",
            "  Downloading wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=0.7.0\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow==1.15) (0.37.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow==1.15) (1.16.0)\n",
            "Collecting h5py\n",
            "  Downloading h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 KB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (59.6.0)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting typing-extensions>=3.6.4\n",
            "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=4c7855d9f89e912fc96b7814ce41e1fa51c9f9e16b84f0e2b7efd9a1d7cb7fd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, zipp, wrapt, typing-extensions, termcolor, protobuf, numpy, MarkupSafe, grpcio, google-pasta, gast, astor, absl-py, werkzeug, opt-einsum, keras-preprocessing, importlib-metadata, h5py, markdown, keras-applications, tensorboard, tensorflow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lazr-restfulclient 0.14.4 requires httplib2>=0.7.7, which is not installed.\n",
            "launchpadlib 1.10.16 requires httplib2, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astor-0.8.1 gast-0.2.2 google-pasta-0.2.0 grpcio-1.62.2 h5py-3.8.0 importlib-metadata-6.7.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.4.4 numpy-1.21.6 opt-einsum-3.3.0 protobuf-4.24.4 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 termcolor-2.3.0 typing-extensions-4.7.1 werkzeug-2.2.3 wrapt-1.16.0 zipp-3.15.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting keras==2.2.4\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.5/312.5 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Collecting scipy>=0.14\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from keras==2.2.4) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.21.6)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (670 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.1/670.1 KB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, pyyaml, keras\n",
            "Successfully installed keras-2.2.4 pyyaml-6.0.1 scipy-1.7.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!sudo apt install python3-pip\n",
        "!sudo apt install python3.7-distutils\n",
        "\n",
        "!pip3 install tensorflow==1.15\n",
        "!pip install keras==2.2.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A9yCWH3PXrpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7adfb6fc-7745-4125-f4ea-01f0b3a6dbc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cav-keras'...\n",
            "remote: Enumerating objects: 369, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 369 (delta 1), reused 0 (delta 0), pack-reused 363\u001b[K\n",
            "Receiving objects: 100% (369/369), 23.58 MiB | 25.74 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n",
            "/content/cav-keras\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pnxenopoulos/cav-keras.git\n",
        "%cd cav-keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z9w14pYtnq6r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar100, cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.abspath('../..'))\n",
        "\n",
        "from cav.tcav import *\n",
        "\n",
        "np.random.seed(1996)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h6Satbp-Xrpj"
      },
      "outputs": [],
      "source": [
        "def extract_airplane_set():\n",
        "    #TODO: Extract the indexes of all the images with 'airplane' as the output label from both train and test.\n",
        "    #TODO: Return the preprocessed sets of both train and test sets\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    a_indexes_train = np.where(y_train == 0)[0]\n",
        "    b_indexes_train = np.where(y_train == 2)[0]\n",
        "    a_indexes_test = np.where(y_test == 0)[0]\n",
        "    b_indexes_test = np.where(y_test == 2)[0]\n",
        "\n",
        "    # Combine airplane and bird indexes\n",
        "    train_indexes = np.concatenate((a_indexes_train, b_indexes_train))\n",
        "    test_indexes = np.concatenate((a_indexes_test, b_indexes_test))\n",
        "\n",
        "    # Select data for training and testing\n",
        "    x_train_ab = x_train[train_indexes]\n",
        "    y_train_ab = y_train[train_indexes]\n",
        "    x_test_ab = x_test[test_indexes]\n",
        "    y_test_ab = y_test[test_indexes]\n",
        "\n",
        "    y_train_ab = (y_train_ab == 0).astype(int)\n",
        "    y_test_ab = (y_test_ab == 0).astype(int)\n",
        "\n",
        "    # Normalize data\n",
        "    x_train_ab = x_train_ab.astype('float32') / 255.0\n",
        "    x_test_ab = x_test_ab.astype('float32') / 255.0\n",
        "\n",
        "    return x_train_ab, y_train_ab, x_test_ab, y_test_ab\n",
        "\n",
        "def extract_cloud_set():\n",
        "    (x_train_concept, y_train_concept), (x_test_concept, y_test_concept) = cifar100.load_data()\n",
        "    #TODO: Extract the indexes of all the images with 'cloud' as the output label for ONLY train set.\n",
        "    #TODO: Return ONLY train set (No preprocess needed)\n",
        "    cloud_indexes = np.where(y_train_concept.flatten() == 23)[0]\n",
        "    x_train_concept_cloud = x_train_concept[cloud_indexes]\n",
        "    y_train_concept_cloud = y_train_concept[cloud_indexes]\n",
        "\n",
        "    return x_train_concept_cloud, y_train_concept_cloud\n",
        "\n",
        "def load_and_transfer_learn():\n",
        "    # Load the ResNet50 model without the top layers\n",
        "    resnet_model = ResNet50(include_top=False, weights='imagenet', input_shape=(32, 32, 3), pooling=None)\n",
        "\n",
        "    # Freeze the pre-trained layers\n",
        "    for layer in resnet_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add custom top layers\n",
        "    model = Sequential()\n",
        "    model.add(resnet_model)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    layers = [\n",
        "        Dense(1024, activation='relu'), Dropout(0.35),\n",
        "        Dense(512, activation='relu'), Dropout(0.25),\n",
        "        Dense(256, activation='relu'), Dropout(0.2),\n",
        "        Dense(128, activation='relu'), Dropout(0.175),\n",
        "        Dense(64, activation='relu'), Dropout(0.125),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ]\n",
        "\n",
        "    for layer in layers:\n",
        "        model.add(layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "def tcav_scores(model, x_train, y_train, x_train_concept, bottleneck):\n",
        "    tf.compat.v1.disable_eager_execution()\n",
        "    tcav_obj = TCAV()\n",
        "    tcav_obj.set_model(model)\n",
        "    tcav_obj.split_model(bottleneck=bottleneck, conv_layer=True)\n",
        "    tcav_obj.train_cav(x_train_concept)\n",
        "    tcav_obj.calculate_sensitivity(x_train, y_train)\n",
        "    tcav_obj.print_sensitivity()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Yz8NS81ko1jb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea1ed03-ec16-440d-cc96-726858cfae3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train, x_test, y_test = extract_airplane_set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6Tjm6tB8o818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019607d7-a340-4dde-c0be-82f9d4ee62bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "x_train_concept, y_train_concept = extract_cloud_set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "H1qThhS5qhAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d939538-508a-4253-a13d-483c62d8749d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 10000 samples\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 486us/sample - loss: 0.7147 - accuracy: 0.5007\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 3s 330us/sample - loss: 0.6949 - accuracy: 0.5008\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 3s 336us/sample - loss: 0.6896 - accuracy: 0.5248\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 3s 327us/sample - loss: 0.6616 - accuracy: 0.5875\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 3s 330us/sample - loss: 0.6459 - accuracy: 0.6202\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fb5663e4610>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model = load_and_transfer_learn()\n",
        "\n",
        "##TODO: Define your choice of batch_size, number of epochs, loss function (e.g. categorical crossentropy), and optimizer (SGD\\Adam)\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "loss_func = 'binary_crossentropy'    #<--- has to be in string format\n",
        "optim = 'adam'       #<--- has to be in string format\n",
        "\n",
        "model.compile(loss=loss_func, optimizer=optim, metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "mOlnXLabq3wr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e312f9f2-d4b3-4394-c9c9-44cb53f5aaf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d_8  (None, 2048)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26383233 (100.64 MB)\n",
            "Trainable params: 2795521 (10.66 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tcav_scores(model, x_train, y_train, x_train_concept, bottleneck=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF3VNu6sVIfa",
        "outputId": "22c7390d-e504-46bd-dc01-9e7e0e32c368"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sensitivity of class 1 is  0.1094\n",
            "The sensitivity of class 0 is  0.9086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tcav_scores(model, x_train, y_train, x_train_concept, bottleneck=7)"
      ],
      "metadata": {
        "id": "EcvXJLt3EE44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13a34d6-40b6-4592-d449-4ab02c47b078"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sensitivity of class 1 is  0.7232\n",
            "The sensitivity of class 0 is  0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tcav_scores(model, x_train, y_train, x_train_concept, bottleneck=11)"
      ],
      "metadata": {
        "id": "fYL3-JTQC3jU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3073a4bc-7bec-4369-92c2-652f917902b6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sensitivity of class 1 is  1.0\n",
            "The sensitivity of class 0 is  0.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4"
    },
    "interpreter": {
      "hash": "e5f42a9c8718f24e54526b98495e71f6224db6b84c40ddfa235e1d4441757c08"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}